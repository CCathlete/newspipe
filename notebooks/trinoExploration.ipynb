{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3eeffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-- [E006] Not Found Error: cmd1.sc:20:9 ----------------------------------------\n",
      "20 |val df = spark.read\n",
      "   |         ^^^^^\n",
      "   |         Not found: spark\n",
      "   |\n",
      "   | longer explanation available when compiling with `-explain`\n",
      "Compilation Failed"
     ]
    }
   ],
   "source": [
    "// 1. Imports\n",
    "import scala.io.Source\n",
    "import org.apache.spark.sql.SparkSession\n",
    "import java.util.Properties\n",
    "\n",
    "// 2. Start Spark session\n",
    "val spark = SparkSession.builder()\n",
    "  .appName(\"TrinoNotebook\")\n",
    "  .master(\"local[*]\")  // for notebooks; adjust for clusters\n",
    "  .getOrCreate()\n",
    "\n",
    "// 3. Load .env file\n",
    "val env = Source.fromFile(\".env\").getLines()\n",
    "  .filter(line => line.nonEmpty && !line.startsWith(\"#\"))\n",
    "  .map { line =>\n",
    "    val Array(key, value) = line.split(\"=\", 2)\n",
    "    key -> value\n",
    "  }.toMap\n",
    "\n",
    "val trinoUrl = env(\"TRINO_URL\")            // e.g., \"jdbc:trino://localhost:8080/hive/default\"\n",
    "val trinoUser = env(\"TRINO_USER\")          // e.g., \"user1\"\n",
    "val trinoPassword = env.getOrElse(\"TRINO_PASSWORD\", \"\")\n",
    "\n",
    "// 4. JDBC properties\n",
    "val trinoProperties = new Properties()\n",
    "trinoProperties.setProperty(\"user\", trinoUser)\n",
    "if(trinoPassword.nonEmpty) trinoProperties.setProperty(\"password\", trinoPassword)\n",
    "\n",
    "// 5. Function to run SQL on Trino and get a DataFrame\n",
    "def trinoQuery(sql: String) = {\n",
    "  spark.read\n",
    "    .jdbc(trinoUrl, s\"($sql) AS subquery\", trinoProperties)\n",
    "}\n",
    "\n",
    "// 6. Example query\n",
    "val df = trinoQuery(\"SELECT * FROM my_silver_table LIMIT 20\")\n",
    "\n",
    "// 7. Display results in notebook\n",
    "display(df)\n",
    "\n",
    "// 8. Optional: print schema\n",
    "df.printSchema()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.13.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
